{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05165c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac23f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# !conda install --yes --prefix {sys.prefix} gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0908d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up N2VEC parameters \n",
    "from topsy_turvy.comparison_methods.n2vec_embedding import compute_embedding\n",
    "\n",
    "\n",
    "test_file   = \"/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/all_nodepairs.tsv\"\n",
    "input_folder  = \"/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets/\"\n",
    "output_folder = \"/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets/\"\n",
    "networks      = [\"network_0.2\", \"network_0.4\", \"network_0.6\", \"network_0.8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ded5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3093"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(test_file, sep = \"\\t\")\n",
    "# Edges\n",
    "(df[\"True_score\"] > 0.5).sum()\n",
    "# Nodes\n",
    "len(set(df[\"node1\"]).union(set(df[\"node2\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3957eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing network /afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//network_0.2\n",
      "Processing network /afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//network_0.4\n",
      "Processing network /afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//network_0.6\n",
      "Processing network /afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//network_0.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>2083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>1960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140</td>\n",
       "      <td>575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>2485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140</td>\n",
       "      <td>835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>2319</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>1224</td>\n",
       "      <td>2779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>2024</td>\n",
       "      <td>2393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>482</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>1047</td>\n",
       "      <td>2771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5426 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p     q  weight\n",
       "0      140  2083       1\n",
       "1      140  1960       1\n",
       "2      140   575       1\n",
       "3      140  2485       1\n",
       "4      140   835       1\n",
       "...    ...   ...     ...\n",
       "5421  2319   602       1\n",
       "5422  1224  2779       1\n",
       "5423  2024  2393       1\n",
       "5424   482   184       1\n",
       "5425  1047  2771       1\n",
       "\n",
       "[5426 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# Given a network file \n",
    "for network in networks:\n",
    "    print(f\"Processing network {input_folder}/{network}\")\n",
    "    net_file       = f\"{input_folder}/{network}.tsv\"\n",
    "    json_file      = f\"{output_folder}/n2vec_{network}.json\"\n",
    "    df    = pd.read_csv(net_file, sep = \"\\t\", header = None)\n",
    "    df.columns = [\"p\", \"q\"]\n",
    "    nodes     = set(df[\"p\"]).union(set(df[\"q\"]))\n",
    "    nodes_map = {node: i for i, node in enumerate(nodes)}\n",
    "    with open(json_file, \"w\") as jf:\n",
    "        json.dump(nodes_map, jf)\n",
    "    df_annotated           = df.replace({\"p\": nodes_map, \"q\": nodes_map})\n",
    "    df_annotated[\"weight\"] = 1\n",
    "    df_annotated.to_csv(f\"{output_folder}/n2vec_annotated_{network}.tsv\", \n",
    "                        header = False, \n",
    "                        index = False, \n",
    "                        sep = \"\\t\")\n",
    "df_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c550d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE2VEC ARGS\n",
    "args      = {}\n",
    "args[\"p\"] = 1\n",
    "args[\"q\"] = 1\n",
    "args[\"dimensions\"] = 300\n",
    "args[\"num_walks\"]  = 10\n",
    "args[\"intermediate_file_loc\"] = f\"{output_folder}/{network}_text_dim_{args['dimensions']}.emb\"\n",
    "args[\"final_emb\"]             = f\"{output_folder}/{network}_emb_dim_{args['dimensions']}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3015943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>2349</td>\n",
       "      <td>0.898801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3283</td>\n",
       "      <td>1459</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1725</td>\n",
       "      <td>1565</td>\n",
       "      <td>0.394838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>455</td>\n",
       "      <td>2894</td>\n",
       "      <td>0.004177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245</td>\n",
       "      <td>19</td>\n",
       "      <td>0.004201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27465</th>\n",
       "      <td>351</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27466</th>\n",
       "      <td>3420</td>\n",
       "      <td>1722</td>\n",
       "      <td>0.987240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27467</th>\n",
       "      <td>1559</td>\n",
       "      <td>1386</td>\n",
       "      <td>0.985707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27468</th>\n",
       "      <td>2287</td>\n",
       "      <td>1202</td>\n",
       "      <td>0.004253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27469</th>\n",
       "      <td>201</td>\n",
       "      <td>389</td>\n",
       "      <td>0.971406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27470 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1         2\n",
       "0       163  2349  0.898801\n",
       "1      3283  1459  0.004207\n",
       "2      1725  1565  0.394838\n",
       "3       455  2894  0.004177\n",
       "4       245    19  0.004201\n",
       "...     ...   ...       ...\n",
       "27465   351     6  0.004178\n",
       "27466  3420  1722  0.987240\n",
       "27467  1559  1386  0.985707\n",
       "27468  2287  1202  0.004253\n",
       "27469   201   389  0.971406\n",
       "\n",
       "[27470 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotated = pd.read_csv(f\"{output_folder}/annotate_{network}.tsv\", sep = \"\\t\", header = None)\n",
    "df_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e7f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = list(df_annotated.to_records(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4818f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the embedding for the network network_0.2\n",
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "{'p': 1, 'q': 1, 'dimensions': 300, 'num_walks': 10, 'intermediate_file_loc': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.2_text_dim_300.emb', 'final_emb': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.2_emb_dim_300.npy', 'input': 'karate.edgelist', 'walk-length': 80, 'num-walks': 10, 'window-size': 10, 'iter': 1, 'workers': 8, 'weighted': True, 'unweighted': False, 'directed': False, 'undirected': True}\n",
      "Here\n",
      "Saving...\n",
      "Computing the embedding for the network network_0.4\n",
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "{'p': 1, 'q': 1, 'dimensions': 300, 'num_walks': 10, 'intermediate_file_loc': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.4_text_dim_300.emb', 'final_emb': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.4_emb_dim_300.npy', 'input': 'karate.edgelist', 'walk-length': 80, 'num-walks': 10, 'window-size': 10, 'iter': 1, 'workers': 8, 'weighted': True, 'unweighted': False, 'directed': False, 'undirected': True}\n",
      "Here\n",
      "Saving...\n",
      "Computing the embedding for the network network_0.6\n",
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "{'p': 1, 'q': 1, 'dimensions': 300, 'num_walks': 10, 'intermediate_file_loc': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.6_text_dim_300.emb', 'final_emb': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.6_emb_dim_300.npy', 'input': 'karate.edgelist', 'walk-length': 80, 'num-walks': 10, 'window-size': 10, 'iter': 1, 'workers': 8, 'weighted': True, 'unweighted': False, 'directed': False, 'undirected': True}\n",
      "Here\n",
      "Saving...\n",
      "Computing the embedding for the network network_0.8\n",
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "{'p': 1, 'q': 1, 'dimensions': 300, 'num_walks': 10, 'intermediate_file_loc': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.8_text_dim_300.emb', 'final_emb': '/afs/csail.mit.edu/u/k/kdevko01/Research/Topsy-Turvy/datasets/Analysis/flydata/data/subnets//n2vec_network_0.8_emb_dim_300.npy', 'input': 'karate.edgelist', 'walk-length': 80, 'num-walks': 10, 'window-size': 10, 'iter': 1, 'workers': 8, 'weighted': True, 'unweighted': False, 'directed': False, 'undirected': True}\n",
      "Here\n",
      "Saving...\n"
     ]
    }
   ],
   "source": [
    "args      = {}\n",
    "args[\"p\"] = 1\n",
    "args[\"q\"] = 1\n",
    "args[\"dimensions\"] = 300\n",
    "args[\"num_walks\"]  = 10\n",
    "\n",
    "def save_emb(args):\n",
    "    with open(args[\"intermediate_file_loc\"], \"r\") as ef:\n",
    "        n_nodes, n_emb = ef.readline().strip().split(\" \")\n",
    "        n_nodes        = int(n_nodes)\n",
    "        n_emb          = int(n_emb)\n",
    "        embeddings     = np.zeros((n_nodes, n_emb))\n",
    "    \n",
    "        for line in ef:\n",
    "            emb        = line.strip().split(\" \")\n",
    "            index      = int(emb[0])\n",
    "            features   = [float(f_i) for f_i in emb[1:]]\n",
    "            embeddings[index] = features\n",
    "    np.save(args[\"final_emb\"], embeddings)\n",
    "\n",
    "for network in networks:\n",
    "    print(f\"Computing the embedding for the network {network}\")\n",
    "    df_annotated = pd.read_csv(f\"{output_folder}/n2vec_annotated_{network}.tsv\", sep = \"\\t\", header = None)\n",
    "    edgelist = list(df_annotated.to_records(index = False))\n",
    "    args[\"intermediate_file_loc\"] = f\"{output_folder}/n2vec_{network}_text_dim_{args['dimensions']}.emb\"\n",
    "    args[\"final_emb\"]             = f\"{output_folder}/n2vec_{network}_emb_dim_{args['dimensions']}.npy\"\n",
    "    embeddings = compute_embedding(edgelist, args)\n",
    "    print(f\"Saving...\")\n",
    "    save_emb(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed228378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "def construct_and_train_model(df, emb):\n",
    "    def compute_neg_set(pos_edges, n_nodes, n_negatives):\n",
    "        neg_set = []\n",
    "        while(len(neg_set) < n_negatives):\n",
    "            p = np.random.randint(n_nodes)\n",
    "            q = np.random.randint(n_nodes)\n",
    "            if p > q:\n",
    "                temp = p\n",
    "                p    = q \n",
    "                q    = temp\n",
    "            if p == q:\n",
    "                continue\n",
    "            if f\"{p}_{q}\" in pos_edges:\n",
    "                continue\n",
    "            neg_set.append((p, q))\n",
    "        return neg_set\n",
    "    \n",
    "    def construct_hadamard(edgelists, n_dim):\n",
    "        features = np.zeros((len(edgelists), n_dim))\n",
    "        for i, (p, q) in enumerate(edgelists):\n",
    "            e1 = emb[p]\n",
    "            e2 = emb[q]\n",
    "            features[i] = e1 * e2\n",
    "        return features\n",
    "            \n",
    "        \n",
    "    df.columns = [\"p\", \"q\", \"w\"]\n",
    "    df.loc[df[\"p\"] >= df[\"q\"], [\"p\", \"q\"]] = df.loc[df[\"p\"] >= df[\"q\"], [\"q\", \"p\"]].values\n",
    "    df[\"p+q\"] = df['p'].astype(str) + \"_\" + df['q'].astype(str)\n",
    "\n",
    "    # All edges\n",
    "    all_edges = set(df[\"p+q\"])\n",
    "    all_nodes = set(df[\"p\"]).union(set(df[\"q\"]))\n",
    "\n",
    "    neg_set = compute_neg_set(all_edges, len(all_nodes), len(all_edges))\n",
    "    pos_set = list(df.loc[:, [\"p\", \"q\"]].to_records(index = False))\n",
    "    \n",
    "    labels  = [0] * len(neg_set) + [1] * len(pos_set)\n",
    "    features = construct_hadamard(neg_set + pos_set, emb.shape[1])\n",
    "    \n",
    "    # Shuffle\n",
    "    shuffle    = np.random.permutation(len(labels))\n",
    "    labels   = np.array(labels)[shuffle]\n",
    "    features = features[shuffle]\n",
    "    \n",
    "    # Create a and fit classifier\n",
    "    clf     = LogisticRegression(random_state = 0).fit(features, labels)\n",
    "    return clf\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0776710",
   "metadata": {},
   "source": [
    "### Training N2VEC embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd78732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def construct_hadamard(edgelists, emb, n_dim):\n",
    "    features = np.zeros((len(edgelists), n_dim))\n",
    "    for i, (p, q) in enumerate(edgelists):\n",
    "        e1 = emb[p]\n",
    "        e2 = emb[q]\n",
    "        features[i] = e1 * e2\n",
    "    return features\n",
    "\n",
    "def filter_train(test_df, trained_df, nodemap):\n",
    "    trained_df.loc[trained_df[0] > trained_df[1], [0, 1]] = trained_df.loc[trained_df[0] > trained_df[1], [1, 0]].values\n",
    "    trained_df[\"p+q\"] = trained_df[0] + \"_\" + trained_df[1]\n",
    "    t_edges_set       = set(trained_df[\"p+q\"])\n",
    "    test_df_f         = test_df[~test_df[\"p+q\"].isin(t_edges_set)]\n",
    "    test_df_a = test_df_f.replace({\"node1\": nodemap, \"node2\": nodemap})\n",
    "    return test_df_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ed2491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Network network_0.2:\n",
      "\t Getting Embedding...\n",
      "\t Using LR classifier and training\n",
      "Performing Prediction...\n",
      "\t ==> Average Precision Score: 0.5749500295818181\n",
      "\n",
      "\n",
      "For Network network_0.4:\n",
      "\t Getting Embedding...\n",
      "\t Using LR classifier and training\n",
      "Performing Prediction...\n",
      "\t ==> Average Precision Score: 0.6647023774785192\n",
      "\n",
      "\n",
      "For Network network_0.6:\n",
      "\t Getting Embedding...\n",
      "\t Using LR classifier and training\n",
      "Performing Prediction...\n",
      "\t ==> Average Precision Score: 0.7213897691631074\n",
      "\n",
      "\n",
      "For Network network_0.8:\n",
      "\t Getting Embedding...\n",
      "\t Using LR classifier and training\n",
      "Performing Prediction...\n",
      "\t ==> Average Precision Score: 0.6819148985068374\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_file, sep  = \"\\t\")\n",
    "test_df[\"p+q\"] = test_df[\"node1\"] + \"_\" + test_df[\"node2\"]\n",
    "\n",
    "for network in networks:\n",
    "    print(f\"For Network {network}:\")\n",
    "    df  = pd.read_csv(f\"{output_folder}/n2vec_annotated_{network}.tsv\", \n",
    "                  sep = \"\\t\", \n",
    "                  header = None)\n",
    "    print(f\"\\t Getting Embedding...\")\n",
    "    emb = np.load(f\"{output_folder}/n2vec_{network}_emb_dim_300.npy\")\n",
    "    print(f\"\\t Using LR classifier and training\")\n",
    "    clf = construct_and_train_model(df, emb)\n",
    "    \n",
    "    # Network Nodemap\n",
    "    with open(f\"{output_folder}/n2vec_{network}.json\", \"r\") as oj:\n",
    "        nodemap = json.load(oj)\n",
    "    \n",
    "    # Train dataframe\n",
    "    trained_df = pd.read_csv(f\"{output_folder}/{network}.tsv\", \n",
    "                         header = None, \n",
    "                         sep = \"\\t\")\n",
    "    \n",
    "    test_df_a  = filter_train(test_df, trained_df, nodemap)\n",
    "    edges    = list(test_df_a.loc[:, [\"node1\", \"node2\"]].to_records(index = False))\n",
    "\n",
    "    features = construct_hadamard(edges, emb, 300)\n",
    "    print(f\"Performing Prediction...\")\n",
    "    results  = clf.predict_proba(features)\n",
    "    p_score  = average_precision_score(test_df_a[\"True_score\"], results[:, 1])\n",
    "    print(f\"\\t ==> Average Precision Score: {p_score}\\n\\n\")\n",
    "    test_df_a[\"n2vec_prediction\"] = results[:, 1]\n",
    "    test_df_a.to_csv(f\"{output_folder}/n2vec_{network}_n2vec_predictions_300.tsv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224670dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
